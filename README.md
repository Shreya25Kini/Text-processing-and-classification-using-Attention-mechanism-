# Text-processing-and-classification-using-Attention-mechanism-
According to reports nearly 80% of the information available today is in un- structured form. The messy nature of textâ€™s sorting and organizing process is pretty time consuming and difficult, there comes the text classification with ML reducing human efforts and with certain predefined algorithms and scripts all the job is done let that be in analyzing survey reports, sales re- ports,etc. Typical RNN/LSTM neural networks consider all words in the text data as important; however, this may not always be true. Hence, we will use the Attention mechanism so that the algorithm focuses on spe- cific words resulting in improved performance. Here we are using sequence transduction models based on complex recurrent or convolutional neural networks that include an encoder and a decoder. We are using Transformer network architecture which is solely based on an attention mechanism. The transformer allows significantly more parallelization in sequential data and requires significantly less time to train.
